{"name":"Tutorial-r","tagline":"Estimate Pi using the R programming language","body":"Table of Contents\r\n----------------\r\n\r\n* [Using R to compute pi on OSG](#Using-R-to-compute-pi-on-OSG)\r\n    * [Overview](#overview)\r\n    * [Accessing R on the submit host](#accessing-r-on-the-submit-host)\r\n    * [Running R code](#running-r-code)\r\n    * [Building the HTCondor job](#building-the-htcondor-job)\r\n    * [Submit and analyze](#submit-and-analyze)\r\n    * [What to do next?](#what-to-do-next)\r\n    * [Help](#help)\r\n\r\n\r\n#Using R to compute pi on OSG\r\n\r\n##Overview\r\nThis tutorial describes how to compute the value of pi using the R statistical package on the OSG. For this example, we'll estimate the value of pi using a Monte Carlo method. We'll first run the program locally as a test.  After that we'll create a submit file, submit it to OSG using OSG Connect, and then collate results when the jobs finish.\r\n\r\n###Background\r\nSome background is useful here. We define a square inscribed by a unit circle. We randomly sample points, and calculate the ratio of the points outside of the circle to the points inside for the first quadrant. This ratio approaches pi/4.\r\n\r\n(See also: http://math.fullerton.edu/mathews/n2003/montecarlopimod.html)\r\n\r\nThis method converges extremely slowly, which makes it great for a CPU-intensive exercise (but bad for a real estimation!).\r\n\r\n##Accessing R on the submit host\r\nFirst we'll need to create a working directory, you can either run *$ tutorial R* or type the following:\r\n````\r\n[user@login01 ~]$ mkdir tutorial-R; cd tutorial-R\r\n````\r\n\r\nFirst, we'll need to set up the system paths so we can access R correctly. This is done via OSG's [Distributed Environment Modules]. To access these modules and access R, enter:\r\n````\r\n[user@login01 ]$ source /cvmfs/oasis.opensciencegrid.org/osg/modules/lmod/5.6.2/init/bash\r\n[user@login01 ]$ module load R\r\n````\r\n\r\nOnce we have the path set up, we can try to run R. Don't worry if you aren't an R expert, I'm not either.\r\n````\r\n[user@login01 ]$ R\r\n \r\nR version 3.1.1 (2014-07-10) -- \"Sock it to Me\"\r\nCopyright (C) 2013 The R Foundation for Statistical Computing\r\nPlatform: x86_64-unknown-linux-gnu (64-bit)\r\nR is free software and comes with ABSOLUTELY NO WARRANTY.\r\nYou are welcome to redistribute it under certain conditions.\r\nType 'license()' or 'licence()' for distribution details.\r\n  Natural language support but running in an English locale\r\nR is a collaborative project with many contributors.\r\nType 'contributors()' for more information and\r\n'citation()' on how to cite R or R packages in publications.\r\nType 'demo()' for some demos, 'help()' for on-line help, or\r\n'help.start()' for an HTML browser interface to help.\r\nType 'q()' to quit R.\r\n \r\n>\r\n````\r\n\r\nGreat! R works. You can quit out with \"q()\". \r\n````\r\n> q()\r\nSave workspace image? [y/n/c]: n\r\n[user@login01 ]$\r\n````\r\n\r\n##Running R code\r\n\r\nNow that we can run R, let's try using the pi estimation code. Create the file *mcpi.R*:\r\n````R\r\n\r\nmontecarloPi <- function(trials) {\r\n  count = 0\r\n  for(i in 1:trials) {\r\n    if((runif(1,0,1)^2 + runif(1,0,1)^2)<1) {\r\n      count = count + 1\r\n    }\r\n  }\r\n  return((count*4)/trials)\r\n}\r\n \r\nmontecarloPi(10000000)\r\n````\r\n\r\nR normally runs as an interactive shell, but it's easy to run in batch mode too.\r\n````\r\n[user@login01 ]$ Rscript --no-save mcpi.R\r\n[1] 3.141956\r\n````\r\n\r\nThis should take few seconds to run. Now edit the file. Increasing the trials ten times (10000000) it will take little over a minute to run, but the estimation still isn't very good. Fortunately, this problem is pleasingly parallel since we're just sampling random points. So what do we need to do to run R on the campus grid?\r\n\r\n##Building the HTCondor job\r\nThe first thing we're going to need to do is create a wrapper for our R environment, based on the setup we did in previous sections. Create the file *R-wrapper.sh*:\r\n````bash\r\n#!/bin/bash\r\n \r\nEXPECTED_ARGS=1\r\n \r\nif [ $# -ne $EXPECTED_ARGS ]; then\r\n  echo \"Usage: R-wrapper.sh file.R\"\r\n  exit 1\r\nelse\r\n  source /cvmfs/oasis.opensciencegrid.org/osg/modules/lmod/5.6.2/init/bash\r\n  module load R\r\n  Rscript $1\r\nfi\r\n````\r\n\r\nNotice here that we're using Rscript (equivalent to R --slave). It accepts the script as command line argument, it makes R much less verbose, and it's easier to parse the output later. If you run it at the command line, you should get similar output as above — but you can run this script without first setting up PALMS. This lets the wrapper launch R on any generic worker node under HTCondor.\r\n````\r\n[user@login01 ]$ ./R-wrapper.sh mcpi.R\r\n[1] 3.142524\r\n````\r\n\r\nNow that we've created a wrapper, let's build a HTCondor submit file around it. We'll call this one *R.submit*:\r\n````\r\nuniverse = vanilla\r\nlog = log/mcpi.log.$(Cluster).$(Process)\r\nerror = log/mcpi.err.$(Cluster).$(Process)\r\noutput = log/mcpi.out.$(Cluster).$(Process)\r\n \r\n# Setup R path, run the mcpi.R script\r\nexecutable = R-wrapper.sh\r\ntransfer_input_files = mcpi.R\r\narguments = mcpi.R\r\n \r\nrequirements = (HAS_CVMFS_oasis_opensciencegrid_org =?= TRUE)\r\nqueue 100 \r\n````\r\n\r\nNotice the requirements line? You'll need to put *HAS_CVMFS_oasis_opensciencegrid_org =?= TRUE* any time you need software from /cvmfs. There's also one small gotcha here – make sure the \"log\" directory used in the submit file exists before you submit! Else HTCondor will fail because it has nowhere to write the logs.\r\n\r\n##Submit and analyze\r\nFinally, submit the job to OSG Connect!\r\n````bash\r\n[user@login01 ]$ condor_submit R.submit\r\nSubmitting job(s)....................................................................................................\r\n100 job(s) submitted to cluster 14027.\r\n[user@login01 ]$ condor_q user\r\n \r\n-- Submitter: login01.osgconnect.net : <128.135.158.173:47839> : login01.osgconnect.net\r\n ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD\r\n14027.0   user           8/25 22:51   0+00:00:43 R  0   0.0  R-wrapper.sh mcpi.\r\n14027.1   user           8/25 22:51   0+00:00:43 R  0   0.0  R-wrapper.sh mcpi.\r\n14027.2   user           8/25 22:51   0+00:00:31 R  0   0.0  R-wrapper.sh mcpi.\r\n14027.4   user           8/25 22:51   0+00:00:41 R  0   0.0  R-wrapper.sh mcpi.\r\n14027.5   user           8/25 22:51   0+00:00:41 R  0   0.0  R-wrapper.sh mcpi.\r\n...\r\n````\r\n\r\nYou can follow the status of your job cluster with the connect watch command, which shows condor_q output that refreshes each 5 seconds.  Press control-C to stop watching.\r\n\r\nSince our jobs just output their results to standard out, we can do the final analysis from the log files. Let's see what one looks like:\r\n````\r\n[user@login01 ]$ cat log/mcpi.out.14027.1\r\n[1] 3.141246\r\n````\r\n\r\nAfter job completion we have 100 Monte Carlo estimates of the value of pi. Taking an average across them all should give us a closer approximation.\r\n\r\nWe'll use a bit of awk magic to do the averaging:\r\n````\r\n[user@login01 ]$ grep \"[1]\" log/mcpi.out.* | awk '{sum += $2} END { print \"Average =\", sum/NR}'\r\nAverage = 3.14151\r\n````\r\n\r\nThat's pretty close! With even more sample sets — that is, more Queue jobs in the cluster — we can statistically come even closer.\r\n\r\n##What to do next?\r\nThe R.submit file may have included a few lines that you are unfamiliar with.  For example, $(Cluster) and $(Process) are variables that will be replaced with the job's cluster and process id.  This is useful when you have many jobs submitted in the same file.  Each output and error file will be in a separate directory.\r\n\r\nAlso, did you notice the transfer_input_files line?  This tells HTCondor what files to transfer with the job to the worker node.  You don't have to tell it to transfer the executable, HTCondor is smart enough to know that the job will need that.  But any extra files, such as our MonteCarlo R file, will need to be explicitly listed to be transferred with the job.  You can use transfer_input_files for input data to the job, as shown in [Transferring data with HTCondor](https://github.com/OSGConnect/tutorial-htcondor_transfer).\r\n\r\n##Help\r\nFor further assistance or questions, please email ***connect-support@opensciencegrid.org***\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}